{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a basic neural network to predict the temperature in Farenheits from Celcius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a tiny dataset to represent the temperatures in celcius(INPUT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celcius_data = np.arange(30)\n",
    "celcius_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate the corresponding temperature in farenheit(LABELS) for the array with celcius data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32. , 33.8, 35.6, 37.4, 39.2, 41. , 42.8, 44.6, 46.4, 48.2, 50. ,\n",
       "       51.8, 53.6, 55.4, 57.2, 59. , 60.8, 62.6, 64.4, 66.2, 68. , 69.8,\n",
       "       71.6, 73.4, 75.2, 77. , 78.8, 80.6, 82.4, 84.2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farenheit_data = (celcius_data * 1.8) + 32\n",
    "farenheit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create 3 layers using keras from tensorflow. We have to pass these layers as arguments to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = tf.keras.layers.Dense(units=1, input_dim=1) \n",
    "l1 = tf.keras.layers.Dense(units=4)\n",
    "l2 = tf.keras.layers.Dense(units=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Sequential Model and adding the three layers to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aksha\\.conda\\envs\\tensorenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([l0, l1, l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model using Mean Squared Error as the loss function and Adam as the optimizer(In place of regular Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aksha\\.conda\\envs\\tensorenv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.losses.MeanSquaredError at 0x1d6372a2208>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the time to fit the model using the input feature and target label.\n",
    "Using 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aksha\\.conda\\envs\\tensorenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "30/30 [==============================] - 0s 7ms/sample - loss: 6682.6299\n",
      "Epoch 2/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 6399.8691\n",
      "Epoch 3/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 6123.5889\n",
      "Epoch 4/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 5853.8950\n",
      "Epoch 5/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 5590.8872\n",
      "Epoch 6/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 5334.6562\n",
      "Epoch 7/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 5085.2847\n",
      "Epoch 8/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4842.8467\n",
      "Epoch 9/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4607.4038\n",
      "Epoch 10/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 4379.0088\n",
      "Epoch 11/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 4157.7041\n",
      "Epoch 12/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 3943.5195\n",
      "Epoch 13/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 3736.4756\n",
      "Epoch 14/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 3536.5796\n",
      "Epoch 15/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 3343.8271\n",
      "Epoch 16/500\n",
      "30/30 [==============================] - 0s 68us/sample - loss: 3158.2024\n",
      "Epoch 17/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 2979.6780\n",
      "Epoch 18/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 2808.2136\n",
      "Epoch 19/500\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 2643.7578\n",
      "Epoch 20/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 2486.2471\n",
      "Epoch 21/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 2335.6062\n",
      "Epoch 22/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 2191.7495\n",
      "Epoch 23/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 2054.5793\n",
      "Epoch 24/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 1923.9875\n",
      "Epoch 25/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 1799.8563\n",
      "Epoch 26/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 1682.0581\n",
      "Epoch 27/500\n",
      "30/30 [==============================] - 0s 31us/sample - loss: 1570.4556\n",
      "Epoch 28/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 1464.9031\n",
      "Epoch 29/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 1365.2472\n",
      "Epoch 30/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 1271.3263\n",
      "Epoch 31/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 1182.9731\n",
      "Epoch 32/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 1100.0140\n",
      "Epoch 33/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 1022.2689\n",
      "Epoch 34/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 949.5549\n",
      "Epoch 35/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 881.6838\n",
      "Epoch 36/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 818.4654\n",
      "Epoch 37/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 759.7065\n",
      "Epoch 38/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 705.2127\n",
      "Epoch 39/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 654.7886\n",
      "Epoch 40/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 608.2388\n",
      "Epoch 41/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 565.3685\n",
      "Epoch 42/500\n",
      "30/30 [==============================] - 0s 31us/sample - loss: 525.9844\n",
      "Epoch 43/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 489.8951\n",
      "Epoch 44/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 456.9116\n",
      "Epoch 45/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 426.8486\n",
      "Epoch 46/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 399.5244\n",
      "Epoch 47/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 374.7617\n",
      "Epoch 48/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 352.3880\n",
      "Epoch 49/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 332.2357\n",
      "Epoch 50/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 314.1436\n",
      "Epoch 51/500\n",
      "30/30 [==============================] - 0s 65us/sample - loss: 297.9557\n",
      "Epoch 52/500\n",
      "30/30 [==============================] - 0s 68us/sample - loss: 283.5228\n",
      "Epoch 53/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 270.7020\n",
      "Epoch 54/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 259.3571\n",
      "Epoch 55/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 249.3585\n",
      "Epoch 56/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 240.5840\n",
      "Epoch 57/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 232.9179\n",
      "Epoch 58/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 226.2516\n",
      "Epoch 59/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 220.4835\n",
      "Epoch 60/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 215.5188\n",
      "Epoch 61/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 211.2693\n",
      "Epoch 62/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 207.6533\n",
      "Epoch 63/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 204.5958\n",
      "Epoch 64/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 202.0275\n",
      "Epoch 65/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 199.8856\n",
      "Epoch 66/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 198.1124\n",
      "Epoch 67/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 196.6560\n",
      "Epoch 68/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 195.4694\n",
      "Epoch 69/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 194.5107\n",
      "Epoch 70/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 193.7424\n",
      "Epoch 71/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 193.1312\n",
      "Epoch 72/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 192.6479\n",
      "Epoch 73/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 192.2669\n",
      "Epoch 74/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 191.9660\n",
      "Epoch 75/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 191.7260\n",
      "Epoch 76/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 191.5305\n",
      "Epoch 77/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 191.3658\n",
      "Epoch 78/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 191.2205\n",
      "Epoch 79/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 191.0849\n",
      "Epoch 80/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 190.9516\n",
      "Epoch 81/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 190.8143\n",
      "Epoch 82/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 190.6686\n",
      "Epoch 83/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 190.5109\n",
      "Epoch 84/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 190.3389\n",
      "Epoch 85/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 190.1510\n",
      "Epoch 86/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 189.9464\n",
      "Epoch 87/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 189.7249\n",
      "Epoch 88/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 189.4869\n",
      "Epoch 89/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 189.2330\n",
      "Epoch 90/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 188.9642\n",
      "Epoch 91/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 188.6816\n",
      "Epoch 92/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 188.3868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "30/30 [==============================] - 0s 65us/sample - loss: 188.0808\n",
      "Epoch 94/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 187.7655\n",
      "Epoch 95/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 187.4421\n",
      "Epoch 96/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 187.1120\n",
      "Epoch 97/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 186.7767\n",
      "Epoch 98/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 186.4372\n",
      "Epoch 99/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 186.0949\n",
      "Epoch 100/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 185.7507\n",
      "Epoch 101/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 185.4056\n",
      "Epoch 102/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 185.0605\n",
      "Epoch 103/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 184.7160\n",
      "Epoch 104/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 184.3726\n",
      "Epoch 105/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 184.0309\n",
      "Epoch 106/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 183.6912\n",
      "Epoch 107/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 183.3539\n",
      "Epoch 108/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 183.0190\n",
      "Epoch 109/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 182.6868\n",
      "Epoch 110/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 182.3573\n",
      "Epoch 111/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 182.0304\n",
      "Epoch 112/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 181.7061\n",
      "Epoch 113/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 181.3842\n",
      "Epoch 114/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 181.0647\n",
      "Epoch 115/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 180.7473\n",
      "Epoch 116/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 180.4320\n",
      "Epoch 117/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 180.1184\n",
      "Epoch 118/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 179.8064\n",
      "Epoch 119/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 179.4957\n",
      "Epoch 120/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 179.1861\n",
      "Epoch 121/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 178.8776\n",
      "Epoch 122/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 178.5697\n",
      "Epoch 123/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 178.2624\n",
      "Epoch 124/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 177.9556\n",
      "Epoch 125/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 177.6489\n",
      "Epoch 126/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 177.3423\n",
      "Epoch 127/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 177.0356\n",
      "Epoch 128/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 176.7287\n",
      "Epoch 129/500\n",
      "30/30 [==============================] - 0s 65us/sample - loss: 176.4216\n",
      "Epoch 130/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 176.1141\n",
      "Epoch 131/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 175.8061\n",
      "Epoch 132/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 175.4976\n",
      "Epoch 133/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 175.1886\n",
      "Epoch 134/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 174.8789\n",
      "Epoch 135/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 174.5686\n",
      "Epoch 136/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 174.2577\n",
      "Epoch 137/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 173.9461\n",
      "Epoch 138/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 173.6338\n",
      "Epoch 139/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 173.3208\n",
      "Epoch 140/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 173.0072\n",
      "Epoch 141/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 172.6928\n",
      "Epoch 142/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 172.3779\n",
      "Epoch 143/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 172.0622\n",
      "Epoch 144/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 171.7459\n",
      "Epoch 145/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 171.4291\n",
      "Epoch 146/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 171.1116\n",
      "Epoch 147/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 170.7935\n",
      "Epoch 148/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 170.4749\n",
      "Epoch 149/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 170.1557\n",
      "Epoch 150/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 169.8361\n",
      "Epoch 151/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 169.5159\n",
      "Epoch 152/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 169.1952\n",
      "Epoch 153/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 168.8740\n",
      "Epoch 154/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 168.5524\n",
      "Epoch 155/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 168.2303\n",
      "Epoch 156/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 167.9077\n",
      "Epoch 157/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 167.5847\n",
      "Epoch 158/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 167.2613\n",
      "Epoch 159/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 166.9375\n",
      "Epoch 160/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 166.6133\n",
      "Epoch 161/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 166.2887\n",
      "Epoch 162/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 165.9637\n",
      "Epoch 163/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 165.6384\n",
      "Epoch 164/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 165.3126\n",
      "Epoch 165/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 164.9865\n",
      "Epoch 166/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 164.6600\n",
      "Epoch 167/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 164.3332\n",
      "Epoch 168/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 164.0061\n",
      "Epoch 169/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 163.6785\n",
      "Epoch 170/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 163.3507\n",
      "Epoch 171/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 163.0225\n",
      "Epoch 172/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 162.6940\n",
      "Epoch 173/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 162.3652\n",
      "Epoch 174/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 162.0360\n",
      "Epoch 175/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 161.7066\n",
      "Epoch 176/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 161.3768\n",
      "Epoch 177/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 161.0468\n",
      "Epoch 178/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 160.7164\n",
      "Epoch 179/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 160.3858\n",
      "Epoch 180/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 160.0549\n",
      "Epoch 181/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 159.7237\n",
      "Epoch 182/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 159.3923\n",
      "Epoch 183/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 159.0606\n",
      "Epoch 184/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 158.7286\n",
      "Epoch 185/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 158.3965\n",
      "Epoch 186/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 158.0640\n",
      "Epoch 187/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 157.7314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 157.3985\n",
      "Epoch 189/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 157.0654\n",
      "Epoch 190/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 156.7321\n",
      "Epoch 191/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 156.3985\n",
      "Epoch 192/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 156.0648\n",
      "Epoch 193/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 155.7309\n",
      "Epoch 194/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 155.3968\n",
      "Epoch 195/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 155.0625\n",
      "Epoch 196/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 154.7281\n",
      "Epoch 197/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 154.3935\n",
      "Epoch 198/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 154.0587\n",
      "Epoch 199/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 153.7238\n",
      "Epoch 200/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 153.3887\n",
      "Epoch 201/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 153.0535\n",
      "Epoch 202/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 152.7181\n",
      "Epoch 203/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 152.3826\n",
      "Epoch 204/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 152.0470\n",
      "Epoch 205/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 151.7112\n",
      "Epoch 206/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 151.3754\n",
      "Epoch 207/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 151.0394\n",
      "Epoch 208/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 150.7034\n",
      "Epoch 209/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 150.3672\n",
      "Epoch 210/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 150.0310\n",
      "Epoch 211/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 149.6946\n",
      "Epoch 212/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 149.3582\n",
      "Epoch 213/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 149.0217\n",
      "Epoch 214/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 148.6851\n",
      "Epoch 215/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 148.3485\n",
      "Epoch 216/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 148.0119\n",
      "Epoch 217/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 147.6751\n",
      "Epoch 218/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 147.3383\n",
      "Epoch 219/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 147.0015\n",
      "Epoch 220/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 146.6647\n",
      "Epoch 221/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 146.3278\n",
      "Epoch 222/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 145.9909\n",
      "Epoch 223/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 145.6539\n",
      "Epoch 224/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 145.3170\n",
      "Epoch 225/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 144.9800\n",
      "Epoch 226/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 144.6431\n",
      "Epoch 227/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 144.3061\n",
      "Epoch 228/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 143.9691\n",
      "Epoch 229/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 143.6322\n",
      "Epoch 230/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 143.2953\n",
      "Epoch 231/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 142.9584\n",
      "Epoch 232/500\n",
      "30/30 [==============================] - 0s 32us/sample - loss: 142.6215\n",
      "Epoch 233/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 142.2846\n",
      "Epoch 234/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 141.9478\n",
      "Epoch 235/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 141.6110\n",
      "Epoch 236/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 141.2743\n",
      "Epoch 237/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 140.9376\n",
      "Epoch 238/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 140.6009\n",
      "Epoch 239/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 140.2644\n",
      "Epoch 240/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 139.9278\n",
      "Epoch 241/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 139.5914\n",
      "Epoch 242/500\n",
      "30/30 [==============================] - 0s 166us/sample - loss: 139.2550\n",
      "Epoch 243/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 138.9187\n",
      "Epoch 244/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 138.5825\n",
      "Epoch 245/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 138.2464\n",
      "Epoch 246/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 137.9103\n",
      "Epoch 247/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 137.5744\n",
      "Epoch 248/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 137.2385\n",
      "Epoch 249/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 136.9028\n",
      "Epoch 250/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 136.5671\n",
      "Epoch 251/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 136.2316\n",
      "Epoch 252/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 135.8962\n",
      "Epoch 253/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 135.5609\n",
      "Epoch 254/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 135.2258\n",
      "Epoch 255/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 134.8907\n",
      "Epoch 256/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 134.5558\n",
      "Epoch 257/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 134.2210\n",
      "Epoch 258/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 133.8864\n",
      "Epoch 259/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 133.5519\n",
      "Epoch 260/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 133.2176\n",
      "Epoch 261/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 132.8834\n",
      "Epoch 262/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 132.5494\n",
      "Epoch 263/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 132.2156\n",
      "Epoch 264/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 131.8819\n",
      "Epoch 265/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 131.5484\n",
      "Epoch 266/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 131.2150\n",
      "Epoch 267/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 130.8819\n",
      "Epoch 268/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 130.5489\n",
      "Epoch 269/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 130.2161\n",
      "Epoch 270/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 129.8834\n",
      "Epoch 271/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 129.5510\n",
      "Epoch 272/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 129.2188\n",
      "Epoch 273/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 128.8868\n",
      "Epoch 274/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 128.5549\n",
      "Epoch 275/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 128.2233\n",
      "Epoch 276/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 127.8920\n",
      "Epoch 277/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 127.5608\n",
      "Epoch 278/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 127.2298\n",
      "Epoch 279/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 126.8991\n",
      "Epoch 280/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 126.5685\n",
      "Epoch 281/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 126.2382\n",
      "Epoch 282/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 125.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 125.5784\n",
      "Epoch 284/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 125.2488\n",
      "Epoch 285/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 124.9194\n",
      "Epoch 286/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 124.5903\n",
      "Epoch 287/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 124.2615\n",
      "Epoch 288/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 123.9329\n",
      "Epoch 289/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 123.6045\n",
      "Epoch 290/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 123.2765\n",
      "Epoch 291/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 122.9487\n",
      "Epoch 292/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 122.6211\n",
      "Epoch 293/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 122.2938\n",
      "Epoch 294/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 121.9668\n",
      "Epoch 295/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 121.6401\n",
      "Epoch 296/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 121.3136\n",
      "Epoch 297/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 120.9875\n",
      "Epoch 298/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 120.6616\n",
      "Epoch 299/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 120.3360\n",
      "Epoch 300/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 120.0106\n",
      "Epoch 301/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 119.6857\n",
      "Epoch 302/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 119.3609\n",
      "Epoch 303/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 119.0365\n",
      "Epoch 304/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 118.7124\n",
      "Epoch 305/500\n",
      "30/30 [==============================] - 0s 133us/sample - loss: 118.3886\n",
      "Epoch 306/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 118.0651\n",
      "Epoch 307/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 117.7419\n",
      "Epoch 308/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 117.4190\n",
      "Epoch 309/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 117.0965\n",
      "Epoch 310/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 116.7742\n",
      "Epoch 311/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 116.4524\n",
      "Epoch 312/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 116.1308\n",
      "Epoch 313/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 115.8095\n",
      "Epoch 314/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 115.4886\n",
      "Epoch 315/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 115.1680\n",
      "Epoch 316/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 114.8478\n",
      "Epoch 317/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 114.5278\n",
      "Epoch 318/500\n",
      "30/30 [==============================] - 0s 99us/sample - loss: 114.2083\n",
      "Epoch 319/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 113.8891\n",
      "Epoch 320/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 113.5702\n",
      "Epoch 321/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 113.2516\n",
      "Epoch 322/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 112.9335\n",
      "Epoch 323/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 112.6157\n",
      "Epoch 324/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 112.2982\n",
      "Epoch 325/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 111.9811\n",
      "Epoch 326/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 111.6644\n",
      "Epoch 327/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 111.3480\n",
      "Epoch 328/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 111.0321\n",
      "Epoch 329/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 110.7164\n",
      "Epoch 330/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 110.4012\n",
      "Epoch 331/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 110.0863\n",
      "Epoch 332/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 109.7718\n",
      "Epoch 333/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 109.4577\n",
      "Epoch 334/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 109.1440\n",
      "Epoch 335/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 108.8306\n",
      "Epoch 336/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 108.5176\n",
      "Epoch 337/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 108.2051\n",
      "Epoch 338/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 107.8929\n",
      "Epoch 339/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 107.5811\n",
      "Epoch 340/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 107.2697\n",
      "Epoch 341/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 106.9587\n",
      "Epoch 342/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 106.6481\n",
      "Epoch 343/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 106.3379\n",
      "Epoch 344/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 106.0282\n",
      "Epoch 345/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 105.7188\n",
      "Epoch 346/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 105.4098\n",
      "Epoch 347/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 105.1012\n",
      "Epoch 348/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 104.7931\n",
      "Epoch 349/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 104.4854\n",
      "Epoch 350/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 104.1780\n",
      "Epoch 351/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 103.8712\n",
      "Epoch 352/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 103.5647\n",
      "Epoch 353/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 103.2587\n",
      "Epoch 354/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 102.9530\n",
      "Epoch 355/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 102.6479\n",
      "Epoch 356/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 102.3431\n",
      "Epoch 357/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 102.0387\n",
      "Epoch 358/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 101.7349\n",
      "Epoch 359/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 101.4314\n",
      "Epoch 360/500\n",
      "30/30 [==============================] - 0s 0s/sample - loss: 101.1284\n",
      "Epoch 361/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 100.8258\n",
      "Epoch 362/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 100.5236\n",
      "Epoch 363/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 100.2219\n",
      "Epoch 364/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 99.9207\n",
      "Epoch 365/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 99.6198\n",
      "Epoch 366/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 99.3195\n",
      "Epoch 367/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 99.0195\n",
      "Epoch 368/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 98.7201\n",
      "Epoch 369/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 98.4211\n",
      "Epoch 370/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 98.1225\n",
      "Epoch 371/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 97.8244\n",
      "Epoch 372/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 97.5268\n",
      "Epoch 373/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 97.2296\n",
      "Epoch 374/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 96.9329\n",
      "Epoch 375/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 96.6366\n",
      "Epoch 376/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 96.3408\n",
      "Epoch 377/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 96.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 95.7506\n",
      "Epoch 379/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 95.4562\n",
      "Epoch 380/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 95.1623\n",
      "Epoch 381/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 94.8688\n",
      "Epoch 382/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 94.5759\n",
      "Epoch 383/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 94.2834\n",
      "Epoch 384/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 93.9913\n",
      "Epoch 385/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 93.6998\n",
      "Epoch 386/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 93.4087\n",
      "Epoch 387/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 93.1181\n",
      "Epoch 388/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 92.8280\n",
      "Epoch 389/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 92.5384\n",
      "Epoch 390/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 92.2493\n",
      "Epoch 391/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 91.9606\n",
      "Epoch 392/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 91.6725\n",
      "Epoch 393/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 91.3848\n",
      "Epoch 394/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 91.0976\n",
      "Epoch 395/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 90.8109\n",
      "Epoch 396/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 90.5247\n",
      "Epoch 397/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 90.2390\n",
      "Epoch 398/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 89.9538\n",
      "Epoch 399/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 89.6691\n",
      "Epoch 400/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 89.3849\n",
      "Epoch 401/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 89.1012\n",
      "Epoch 402/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 88.8180\n",
      "Epoch 403/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 88.5353\n",
      "Epoch 404/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 88.2531\n",
      "Epoch 405/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 87.9714\n",
      "Epoch 406/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 87.6902\n",
      "Epoch 407/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 87.4095\n",
      "Epoch 408/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 87.1293\n",
      "Epoch 409/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 86.8496\n",
      "Epoch 410/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 86.5705\n",
      "Epoch 411/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 86.2918\n",
      "Epoch 412/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 86.0136\n",
      "Epoch 413/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 85.7360\n",
      "Epoch 414/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 85.4589\n",
      "Epoch 415/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 85.1823\n",
      "Epoch 416/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 84.9062\n",
      "Epoch 417/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 84.6306\n",
      "Epoch 418/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 84.3556\n",
      "Epoch 419/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 84.0810\n",
      "Epoch 420/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 83.8070\n",
      "Epoch 421/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 83.5335\n",
      "Epoch 422/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 83.2606\n",
      "Epoch 423/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 82.9881\n",
      "Epoch 424/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 82.7162\n",
      "Epoch 425/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 82.4448\n",
      "Epoch 426/500\n",
      "30/30 [==============================] - 0s 101us/sample - loss: 82.1739\n",
      "Epoch 427/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 81.9035\n",
      "Epoch 428/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 81.6337\n",
      "Epoch 429/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 81.3644\n",
      "Epoch 430/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 81.0956\n",
      "Epoch 431/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 80.8274\n",
      "Epoch 432/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 80.5597\n",
      "Epoch 433/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 80.2925\n",
      "Epoch 434/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 80.0258\n",
      "Epoch 435/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 79.7597\n",
      "Epoch 436/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 79.4941\n",
      "Epoch 437/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 79.2291\n",
      "Epoch 438/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 78.9646\n",
      "Epoch 439/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 78.7006\n",
      "Epoch 440/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 78.4372\n",
      "Epoch 441/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 78.1742\n",
      "Epoch 442/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 77.9118\n",
      "Epoch 443/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 77.6500\n",
      "Epoch 444/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 77.3887\n",
      "Epoch 445/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 77.1279\n",
      "Epoch 446/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 76.8677\n",
      "Epoch 447/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 76.6080\n",
      "Epoch 448/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 76.3489\n",
      "Epoch 449/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 76.0903\n",
      "Epoch 450/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 75.8322\n",
      "Epoch 451/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 75.5747\n",
      "Epoch 452/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 75.3178\n",
      "Epoch 453/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 75.0613\n",
      "Epoch 454/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 74.8055\n",
      "Epoch 455/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 74.5501\n",
      "Epoch 456/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 74.2953\n",
      "Epoch 457/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 74.0411\n",
      "Epoch 458/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 73.7874\n",
      "Epoch 459/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 73.5342\n",
      "Epoch 460/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 73.2816\n",
      "Epoch 461/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 73.0295\n",
      "Epoch 462/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 72.7780\n",
      "Epoch 463/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 72.5271\n",
      "Epoch 464/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 72.2766\n",
      "Epoch 465/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 72.0268\n",
      "Epoch 466/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 71.7775\n",
      "Epoch 467/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 71.5287\n",
      "Epoch 468/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 71.2804\n",
      "Epoch 469/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 71.0328\n",
      "Epoch 470/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 70.7857\n",
      "Epoch 471/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 70.5391\n",
      "Epoch 472/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 70.2931\n",
      "Epoch 473/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 70.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 69.8027\n",
      "Epoch 475/500\n",
      "30/30 [==============================] - 0s 2ms/sample - loss: 69.5583\n",
      "Epoch 476/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 69.3145\n",
      "Epoch 477/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 69.0713\n",
      "Epoch 478/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 68.8286\n",
      "Epoch 479/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 68.5864\n",
      "Epoch 480/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 68.3448\n",
      "Epoch 481/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 68.1038\n",
      "Epoch 482/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 67.8633\n",
      "Epoch 483/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 67.6234\n",
      "Epoch 484/500\n",
      "30/30 [==============================] - 0s 100us/sample - loss: 67.3840\n",
      "Epoch 485/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 67.1452\n",
      "Epoch 486/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 66.9069\n",
      "Epoch 487/500\n",
      "30/30 [==============================] - 0s 34us/sample - loss: 66.6692\n",
      "Epoch 488/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 66.4321\n",
      "Epoch 489/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 66.1955\n",
      "Epoch 490/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 65.9594\n",
      "Epoch 491/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 65.7240\n",
      "Epoch 492/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 65.4890\n",
      "Epoch 493/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 65.2546\n",
      "Epoch 494/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 65.0208\n",
      "Epoch 495/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 64.7876\n",
      "Epoch 496/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 64.5549\n",
      "Epoch 497/500\n",
      "30/30 [==============================] - 0s 33us/sample - loss: 64.3227\n",
      "Epoch 498/500\n",
      "30/30 [==============================] - 0s 66us/sample - loss: 64.0911\n",
      "Epoch 499/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 63.8601\n",
      "Epoch 500/500\n",
      "30/30 [==============================] - 0s 67us/sample - loss: 63.6296\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(celcius_data, farenheit_data, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d6389c0630>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will plot the magnitude of loss against the epoch number which show the trend of loss from each epoch\n",
    "\"\"\"\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss Magnitude')\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 500,\n",
       " 'steps': None,\n",
       " 'samples': 30,\n",
       " 'verbose': 1,\n",
       " 'do_validation': False,\n",
       " 'metrics': ['loss']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, predicting the value for a new celcius value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[276.5297]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorenv] *",
   "language": "python",
   "name": "conda-env-tensorenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
